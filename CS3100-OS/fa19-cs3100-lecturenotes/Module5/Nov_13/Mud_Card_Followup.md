# Mud Card Follow-Up from November 13

## Pages and frames

> Is a page a section of memory, or the data stored in memory?

I'm having a hard time deciding how to describe the distinction.

Most often I'd say that the term "page" refers to a quantity of memory (usually
it's 4kb).  However, I can think of plenty of times speakers and books use
the word "page" to refer to the contents of that chunk of memory.

I guess it's analagous to how we might use that word to describe content on
paper.  We all understand how much text can fit on one page, so we'll describe
a book as being so many "pages" long.  But we sometimes say "page" to talk
about specific content.


> How many pages to a frame?

Usually it's a one-to-one mapping, but there is an important **but** to this
explanation..  Refer back to the diagram in the discussion from Monday 11/11
about [Shared
Pages](https://gitlab.cs.usu.edu/erik.falor/fa19-cs3100-lecturenotes/blob/master/Module5/Nov_08/README.md#854-shared-pages)

Under shared pages, you'll see that several processes each have their own
"page" of a process's text section that is actually stored in the same frame.
As long as that page is read-only (or writable under Copy-on-Write), they can
all use the same physical frame without any problem.


> Is there a way to switch between Copy-on-Write and sharing memory depending
> on what the child process becomes?

In Unix-derived OSes there is.  Section 9.3 "Copy-on-Write" describes the Unix
system call `vfork()` which is like `fork()` without COW.  It is explicitly
intended to be used in the situation I described in class: where the child
process immediately calls `exec()` to become a different process.

> I'm not sure how to visualize paging.

https://www.youtube.com/watch?v=yP-OvorryAU

Seriously, maybe this video will help: https://www.youtube.com/watch?v=qlH4-oHnBb8


## Page faults

> Is a swap a page fault?

Technically these are different things.  "Swap" originally meant to copy the
*entire* memory space of a process to or from the backing store; an
all-or-nothing proposition.  Paging means to do this in a fine-grained way,
such that only *part* of a process would be on disk.

I hope I don't use the terms in a confusing way, but I have the feeling that
folks use the terms interchangably these days.  There are no mainstream OSes
that do wholesale swapping of entire processes anymore.


> So, a page is virtual memory.  A frame is a physical address in RAM.  But the
> actual memory that's being loaded is on disk (hard disk, SSD, etc.)?

Yep, that's it.  Any data in RAM originally came from the HD, whether it is raw
data copied straight from the disk, or data that was generated by a process...
that process was originally a program sitting on a disk before it was
executed.


> How do you solve the problem if you need all of the memory?  Wouldn't it
> always have to retrieve it from the HD?

As you'll see next week, we can use RAM for storing processes' data or for
caching data from the disk.  Of the two, process data is more critical to keep
in RAM.  Cached files are a nice bonus, but must be discarded in favor of the
live data of a process.


> If you are processing a large image (using on-demand paging) and only pull
> parts of it in (processing from top to bottom) at what point does it take
> more time to do all of the context switches to load the image piece by piece,
> rather than just loading the entire image at once?

I'll assume that in this scenario that the program will process every single
pixel of the image in one pass, from begininng to end.  The time needed will
depend on many factors:

0. The system load
1. How much RAM is available
2. How fast the storage hardware is
3. How large the image is

You'd have to run some experiments to find that tipping point.  In practice,
*prepaging* (textbook section 9.9.1) would likely be used by your computer,
further confusing your benchmarks.


> Do things like Intel Optane (essentially a M.2) help avoid page faults, or is
> it just faster than disk?

I'm not super-familiar with Optane, but it sounds like it's just another layer
of cache that sits between the hard disk and RAM.  If it's M.2 storage, it's
essentially a mini SSD that augments your RAM.  If the OS uses it
intelligently, that is, to cache data and files you're likely to need while the
system is otherwise idle, it would speed things up (see textbook section 9.9.1
Prepaging).  If it can remember those things between reboots, that would save
time later.  But since the data must come from your HD at some point, you have
to pay the price of loading it at least once.


> Does throwing more RAM at this problem really help?  Or does the OS still
> overfill it and run into the same problems?

In my experience, on Linux, adding more RAM absolutely helps.  You really only
run into problems when you try to run too many processes at a time, or many
bloated processs at once.


> Do lighter OSes allow you to need to swap less?

Lighter processes in general help here.



## Belady's Anomaly

> Why does Belady's anomaly happen?

> How can more memory create more page faults?

This is covered in greater depth in the text book in section 9.4.2.  We'll
discuss it next week as we prepare for the final assignment where you can
experience it for yourself, and in conjunction with the different
page-replacement algorithms.

TL;DR: it mostly occurs in the FIFO page replacement algorithm; for the other
algorithms that we'll study it is provable that they *cannot* suffer from it.
## Profiling and Optimization

> Other than the printing method, are there good ways to benchmark pieces of
> code?

> Can you expand on compiler profiling and ho wwe do that/use it?

> What is the best way to minimize the amount of memory we are using? (In
> general, and in Java)

I don't mean to take off on a tangent, but since you asked...



### Java profiling

Java profilers seem to be bulit to profile the performance of the managed
memory system instead of the CPU efficiency of code.  These tools will help you
identify where you using the most memory, suggesting places to cut back.


The Java profilers that I've used are interactive GUI programs which you attach
to a running Java program.  They display pretty graphs about such things as
%CPU utilization, memory utilization and performance of the Garbage Collector
(GC).  Information about running threads is visible.  You may be able to figure
out which thread(s) slow your program down, but finding out which methods take
a long time to run may not be straightforward.


*   I've used [VisualVM](https://visualvm.github.io/documentation.html) to
    track down memory leaks and deadlocks.  I could have sworn that this tool
    was included with the JDK, but it's not present in my Java12 installation.
    You can download it for free from GitHub.


*   `jconsole` is included with Java12.  Look in the `bin/` directory of your
    Java installation.  It strikes me as a poor-man's VisualVM, but I haven't
    spent a ton of time looking at it.  There are other useful programs in
    Java's `bin/` directory and you should explore these.


*   IntelliJ apparently has some profiling tools, but as far as I can tell they
    exist only in the Ultimate edition.


### C and C++

In the C and C++ world, profiling means timing the duration of function calls.
There are tools to observe memory allocation patterns, but the emphasis is
generally on execution speed of code.

Profiling is achieved by re-compiling a program to add extra instructions
before and after function calls which write timing information into a special
file called `gmon.out`.  After the program finishes, an external program called
`gprof` is used to analyze and report on the contents of `gmon.out`.

Because profiling is achieved by adding extra code to the program it can affect
performance and might even introduce or mask race conditions.  An executable
compiled for profiling purposes wouldn't ordinarily be shipped to customers.

You can try this out on your Raspberry Pi with the `cow` example from this
lecture:

0.  Edit Makefile and add `-pg` to the `CXXFLAGS` variable:

        CXXFLAGS = -std=c++14 -pg

1.  Rebuild the application by running `make`

2.  Run the program to completion

3.  Analyze the output of the profiling process `gmon.out`

        gprof cow gmon.out

